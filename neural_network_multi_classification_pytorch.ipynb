{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOm8UcitX/7HD4+Bl9mgCNc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ahmed1010-1999/deep_learnig/blob/main/neural_network_multi_classification_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Po-VEKxl1LdL",
        "outputId": "22c06d5b-a9ea-4e45-a1d2-883acf0dcf45"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([3, 2, 2, 1, 1, 2, 1, 2, 2, 1, 1, 3, 0, 2, 2, 2, 0, 0, 0, 1, 1, 3, 3, 3,\n",
            "        1, 1, 0, 0, 2, 1])\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import make_blobs\n",
        "from sklearn.model_selection import train_test_split\n",
        "def softmax(input_w: torch.Tensor)->torch.Tensor:\n",
        "  z=torch.exp(input_w)\n",
        "\n",
        "  d=torch.sum(z,dim=1)\n",
        "  d = z / d[:, None]\n",
        "  return d\n",
        "\n",
        "# Set the hyperparameters for data creation\n",
        "NUM_CLASSES = 4\n",
        "NUM_FEATURES = 2\n",
        "RANDOM_SEED = 42\n",
        "\n",
        "# 1. Create multi-class data\n",
        "X_blob, y_blob = make_blobs(n_samples=1000,\n",
        "    n_features=NUM_FEATURES, # X features\n",
        "    centers=NUM_CLASSES, # y labels\n",
        "    cluster_std=1.5, # give the clusters a little shake up (try changing this to 1.0, the default)\n",
        "    random_state=RANDOM_SEED\n",
        ")\n",
        "\n",
        "# 2. Turn data into tensors\n",
        "X_blob = torch.from_numpy(X_blob).type(torch.float)\n",
        "y_blob = torch.from_numpy(y_blob).type(torch.LongTensor)\n",
        "#print(X_blob[:5], y_blob[:5])\n",
        "\n",
        "# 3. Split into train and test sets\n",
        "X_blob_train, X_blob_test, y_blob_train, y_blob_test = train_test_split(X_blob,\n",
        "    y_blob,\n",
        "    test_size=0.2,\n",
        "    random_state=RANDOM_SEED\n",
        ")\n",
        "print(y_blob[:30])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Build model\n",
        "class BlobModel(nn.Module):\n",
        "    def __init__(self, input_features, output_features, hidden_units=8):\n",
        "        super().__init__()\n",
        "        self.linear_layer_stack = nn.Sequential(\n",
        "            nn.Linear(in_features=input_features, out_features=hidden_units),\n",
        "\n",
        "            nn.Linear(in_features=hidden_units, out_features=hidden_units),\n",
        "\n",
        "            nn.Linear(in_features=hidden_units, out_features=output_features),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.linear_layer_stack(x)\n",
        "\n",
        "# Create an instance of BlobModel and send it to the target device\n",
        "model_4 = BlobModel(input_features=NUM_FEATURES,\n",
        "                    output_features=NUM_CLASSES,\n",
        "                    hidden_units=8)"
      ],
      "metadata": {
        "id": "pzfiH8d21bSr"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create loss and optimizer\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model_4.parameters(),\n",
        "                            lr=0.1) # exercise: try changing the learning rate here and seeing what happens to the model's performance"
      ],
      "metadata": {
        "id": "NUQu9dP81wjd"
      },
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform a single forward pass on the data (we'll need to put it to the target device for it to work)\n",
        "model_4(X_blob_train)[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "050godnN10Ip",
        "outputId": "72301d2e-35ed-41bd-96f2-9316d5837c7c"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1.1010,  0.5867, -0.8381,  0.7735],\n",
              "        [ 0.9743, -3.1038,  0.5808,  2.0448],\n",
              "        [-1.7637, -0.7465,  2.3091, -1.8137],\n",
              "        [-0.9728, -1.0193,  1.6660, -0.8549],\n",
              "        [ 0.6359, -2.8051,  0.7918,  1.5651]], grad_fn=<SliceBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make prediction logits with model\n",
        "y_logits = model_4(X_blob_test)\n",
        "\n",
        "d=softmax(y_logits[:5])\n",
        "\n",
        "print(d)\n",
        "print('===============')\n",
        "print('===============')\n",
        "print('===============')\n",
        "print('===============')\n",
        "# Perform softmax calculation on logits across dimension 1 to get\n",
        "y_pred_probs = torch.softmax(y_logits, dim=1)\n",
        "print(y_logits[:5])\n",
        "print(y_pred_probs[:5])\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t7G9VQ-Y16R2",
        "outputId": "74d4089d-0909-49b8-cc12-d273990601c4"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.4256, 0.1594, 0.0584, 0.3566],\n",
            "        [0.0965, 0.0014, 0.5140, 0.3881],\n",
            "        [0.0342, 0.0981, 0.8390, 0.0287],\n",
            "        [0.3425, 0.3224, 0.1019, 0.2333],\n",
            "        [0.2714, 0.0060, 0.0765, 0.6461]], grad_fn=<DivBackward0>)\n",
            "===============\n",
            "===============\n",
            "===============\n",
            "===============\n",
            "tensor([[ 1.1940,  0.2118, -0.7930,  1.0172],\n",
            "        [ 0.0936, -4.1314,  1.7660,  1.4851],\n",
            "        [-1.3870, -0.3346,  1.8118, -1.5638],\n",
            "        [ 0.7131,  0.6526, -0.4988,  0.3292],\n",
            "        [ 1.3155, -2.4986,  0.0485,  2.1827]], grad_fn=<SliceBackward0>)\n",
            "tensor([[0.4256, 0.1594, 0.0584, 0.3566],\n",
            "        [0.0965, 0.0014, 0.5140, 0.3881],\n",
            "        [0.0342, 0.0981, 0.8390, 0.0287],\n",
            "        [0.3425, 0.3224, 0.1019, 0.2333],\n",
            "        [0.2714, 0.0060, 0.0765, 0.6461]], grad_fn=<SliceBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sum the first sample output of the softmax activation function\n",
        "torch.sum(y_pred_probs[0]),torch.sum(d[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hyTtKXDg2AZN",
        "outputId": "da462a66-c70f-403d-b36f-aa600c7fe675"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(1., grad_fn=<SumBackward0>), tensor(1., grad_fn=<SumBackward0>))"
            ]
          },
          "metadata": {},
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Which class does the model think is *most* likely at the index 0 sample?\n",
        "print(y_pred_probs[0])\n",
        "print(torch.argmax(y_pred_probs[0]))\n",
        "print(d[0])\n",
        "print(torch.argmax(d[0]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TNhhJQol2B0d",
        "outputId": "e40acdde-dd79-4439-f1ff-997c0a133c25"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.4256, 0.1594, 0.0584, 0.3566], grad_fn=<SelectBackward0>)\n",
            "tensor(0)\n",
            "tensor([0.4256, 0.1594, 0.0584, 0.3566], grad_fn=<SelectBackward0>)\n",
            "tensor(0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy_fn(y_true,y_pred):\n",
        "  correct=torch.eq(y_true,y_pred).sum().item()\n",
        "  acc=(correct/len(y_pred))*100\n",
        "  return acc\n"
      ],
      "metadata": {
        "id": "K1bQ-2kE2Z5X"
      },
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# Set number of epochs\n",
        "epochs = 100\n",
        "\n",
        "\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    ### Training\n",
        "    model_4.train()\n",
        "\n",
        "    # 1. Forward pass\n",
        "    y_logits = model_4(X_blob_train) # model outputs raw logits\n",
        "    y_pred = torch.softmax(y_logits, dim=1).argmax(dim=1) # go from logits -> prediction probabilities -> prediction labels\n",
        "    # print(y_logits)\n",
        "    # 2. Calculate loss and accuracy\n",
        "    loss = loss_fn(y_logits, y_blob_train)\n",
        "    acc = accuracy_fn(y_true=y_blob_train,\n",
        "                      y_pred=y_pred)\n",
        "\n",
        "    # 3. Optimizer zero grad\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # 4. Loss backwards\n",
        "    loss.backward()\n",
        "\n",
        "    # 5. Optimizer step\n",
        "    optimizer.step()\n",
        "\n",
        "    ### Testing\n",
        "    model_4.eval()\n",
        "    with torch.inference_mode():\n",
        "      # 1. Forward pass\n",
        "      test_logits = model_4(X_blob_test)\n",
        "      test_pred = torch.softmax(test_logits, dim=1).argmax(dim=1)\n",
        "      # 2. Calculate test loss and accuracy\n",
        "      test_loss = loss_fn(test_logits, y_blob_test)\n",
        "      test_acc = accuracy_fn(y_true=y_blob_test,\n",
        "                             y_pred=test_pred)\n",
        "\n",
        "    # Print out what's happening\n",
        "    if epoch % 10 == 0:\n",
        "        print(f\"Epoch: {epoch} | Loss: {loss:.5f}, Acc: {acc:.2f}% | Test Loss: {test_loss:.5f}, Test Acc: {test_acc:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mgXZFFDR2DrL",
        "outputId": "3e101fdb-66fa-471b-b9b4-a367f1408f0d"
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 | Loss: 0.03255, Acc: 99.12% | Test Loss: 0.02377, Test Acc: 99.50%\n",
            "Epoch: 10 | Loss: 0.03171, Acc: 99.12% | Test Loss: 0.02279, Test Acc: 99.50%\n",
            "Epoch: 20 | Loss: 0.03103, Acc: 99.12% | Test Loss: 0.02197, Test Acc: 99.50%\n",
            "Epoch: 30 | Loss: 0.03046, Acc: 99.12% | Test Loss: 0.02128, Test Acc: 99.50%\n",
            "Epoch: 40 | Loss: 0.02998, Acc: 99.12% | Test Loss: 0.02068, Test Acc: 99.50%\n",
            "Epoch: 50 | Loss: 0.02956, Acc: 99.12% | Test Loss: 0.02016, Test Acc: 99.50%\n",
            "Epoch: 60 | Loss: 0.02920, Acc: 99.12% | Test Loss: 0.01970, Test Acc: 99.50%\n",
            "Epoch: 70 | Loss: 0.02889, Acc: 99.12% | Test Loss: 0.01929, Test Acc: 99.50%\n",
            "Epoch: 80 | Loss: 0.02861, Acc: 99.12% | Test Loss: 0.01893, Test Acc: 99.50%\n",
            "Epoch: 90 | Loss: 0.02836, Acc: 99.12% | Test Loss: 0.01860, Test Acc: 99.50%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy_fn(y_true,y_pred):\n",
        "  correct=torch.eq(y_true,y_pred).sum().item()\n",
        "  acc=(correct/len(y_pred))*100\n",
        "  return acc\n"
      ],
      "metadata": {
        "id": "pjg-3j3O2NXb"
      },
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn predicted logits in prediction probabilities\n",
        "y_pred_probs = torch.softmax(y_logits, dim=1)\n",
        "\n",
        "# Turn prediction probabilities into prediction labels\n",
        "y_preds = y_pred_probs.argmax(dim=1)\n",
        "\n",
        "# Compare first 10 model preds and test labels\n",
        "print(f\"Predictions: {y_preds[:10]}\\nLabels: {y_blob_test[:10]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WqxqY8gu2Nae",
        "outputId": "97c9b25b-b625-44e4-d10e-36dab0c98d66"
      },
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions: tensor([1, 0, 2, 2, 0, 0, 0, 1, 3, 0])\n",
            "Labels: tensor([1, 3, 2, 1, 0, 3, 2, 0, 2, 0])\n"
          ]
        }
      ]
    }
  ]
}